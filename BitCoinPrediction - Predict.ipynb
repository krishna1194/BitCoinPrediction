{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nstigiz9ZHDe"
      },
      "source": [
        "# Total Run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLOncNpJZNhS"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZwJiDdQY7cK",
        "outputId": "f015500b-f327-4911-9ecb-c42c3d4a19a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-utils in /usr/local/lib/python3.7/dist-packages (3.3.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cryptocmd\n",
            "  Downloading cryptocmd-0.6.1-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from cryptocmd) (2.23.0)\n",
            "Collecting tablib\n",
            "  Downloading tablib-3.2.1-py3-none-any.whl (48 kB)\n",
            "\u001b[K     |████████████████████████████████| 48 kB 1.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->cryptocmd) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->cryptocmd) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->cryptocmd) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->cryptocmd) (3.0.4)\n",
            "Installing collected packages: tablib, cryptocmd\n",
            "Successfully installed cryptocmd-0.6.1 tablib-3.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install python-utils\n",
        "!pip install cryptocmd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poZeRypfZTjg",
        "outputId": "0a91b584-f278-4295-c443-16ffca6eda9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.9.2\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "from math import sqrt\n",
        "\n",
        "import lightgbm as lgb\n",
        "import matplotlib as mpl\n",
        "import numpy as np\n",
        "import pandas as pd  # Basic library for all of our dataset operations\n",
        "import statsmodels as sm\n",
        "import tensorflow as tf\n",
        "import xgboost as xgb\n",
        "from matplotlib import pyplot as plt\n",
        "from pylab import rcParams\n",
        "from sklearn import linear_model, svm\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import make_scorer, mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tqdm import tqdm\n",
        "import datetime\n",
        "\n",
        "\n",
        "# We will use deprecated models of statmodels which throw a lot of warnings to use more modern ones\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "# Extra settings\n",
        "seed = 42\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n",
        "plt.style.use('bmh')\n",
        "mpl.rcParams['axes.labelsize'] = 14\n",
        "mpl.rcParams['xtick.labelsize'] = 12\n",
        "mpl.rcParams['ytick.labelsize'] = 12\n",
        "mpl.rcParams['text.color'] = 'k'\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ukKtZ7BvZhmZ"
      },
      "outputs": [],
      "source": [
        "#Evaluation Metrics\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "EPSILON = 1e-10\n",
        "\n",
        "\n",
        "def _error(actual: np.ndarray, predicted: np.ndarray):\n",
        "    \"\"\"Simple error\"\"\"\n",
        "    return actual - predicted\n",
        "\n",
        "\n",
        "def _percentage_error(actual: np.ndarray, predicted: np.ndarray):\n",
        "    \"\"\"\n",
        "    Percentage error\n",
        "    Note: result is NOT multiplied by 100\n",
        "    \"\"\"\n",
        "    return _error(actual, predicted) / (actual + EPSILON)\n",
        "\n",
        "\n",
        "def _naive_forecasting(actual: np.ndarray, seasonality: int = 1):\n",
        "    \"\"\"Naive forecasting method which just repeats previous samples\"\"\"\n",
        "    return actual[:-seasonality]\n",
        "\n",
        "\n",
        "def _relative_error(\n",
        "    actual: np.ndarray, predicted: np.ndarray, benchmark: np.ndarray = None\n",
        "):\n",
        "    \"\"\"Relative Error\"\"\"\n",
        "    if benchmark is None or isinstance(benchmark, int):\n",
        "        # If no benchmark prediction provided - use naive forecasting\n",
        "        if not isinstance(benchmark, int):\n",
        "            seasonality = 1\n",
        "        else:\n",
        "            seasonality = benchmark\n",
        "        return _error(actual[seasonality:], predicted[seasonality:]) / (\n",
        "            _error(actual[seasonality:], _naive_forecasting(actual, seasonality))\n",
        "            + EPSILON\n",
        "        )\n",
        "\n",
        "    return _error(actual, predicted) / (_error(actual, benchmark) + EPSILON)\n",
        "\n",
        "\n",
        "def _bounded_relative_error(\n",
        "    actual: np.ndarray, predicted: np.ndarray, benchmark: np.ndarray = None\n",
        "):\n",
        "    \"\"\"Bounded Relative Error\"\"\"\n",
        "    if benchmark is None or isinstance(benchmark, int):\n",
        "        # If no benchmark prediction provided - use naive forecasting\n",
        "        if not isinstance(benchmark, int):\n",
        "            seasonality = 1\n",
        "        else:\n",
        "            seasonality = benchmark\n",
        "\n",
        "        abs_err = np.abs(_error(actual[seasonality:], predicted[seasonality:]))\n",
        "        abs_err_bench = np.abs(\n",
        "            _error(actual[seasonality:], _naive_forecasting(actual, seasonality))\n",
        "        )\n",
        "    else:\n",
        "        abs_err = np.abs(_error(actual, predicted))\n",
        "        abs_err_bench = np.abs(_error(actual, benchmark))\n",
        "\n",
        "    return abs_err / (abs_err + abs_err_bench + EPSILON)\n",
        "\n",
        "\n",
        "def _geometric_mean(a, axis=0, dtype=None):\n",
        "    \"\"\"Geometric mean\"\"\"\n",
        "    if not isinstance(a, np.ndarray):  # if not an ndarray object attempt to convert it\n",
        "        log_a = np.log(np.array(a, dtype=dtype))\n",
        "    elif dtype:  # Must change the default dtype allowing array type\n",
        "        if isinstance(a, np.ma.MaskedArray):\n",
        "            log_a = np.log(np.ma.asarray(a, dtype=dtype))\n",
        "        else:\n",
        "            log_a = np.log(np.asarray(a, dtype=dtype))\n",
        "    else:\n",
        "        log_a = np.log(a)\n",
        "    return np.exp(log_a.mean(axis=axis))\n",
        "\n",
        "\n",
        "def mse(actual: np.ndarray, predicted: np.ndarray):\n",
        "    \"\"\"Mean Squared Error\"\"\"\n",
        "    return np.mean(np.square(_error(actual, predicted)))\n",
        "\n",
        "\n",
        "def rmse(actual: np.ndarray, predicted: np.ndarray):\n",
        "    \"\"\"Root Mean Squared Error\"\"\"\n",
        "    return np.sqrt(mse(actual, predicted))\n",
        "\n",
        "\n",
        "def nrmse(actual: np.ndarray, predicted: np.ndarray):\n",
        "    \"\"\"Normalized Root Mean Squared Error\"\"\"\n",
        "    return rmse(actual, predicted) / (actual.max() - actual.min())\n",
        "\n",
        "\n",
        "def me(actual: np.ndarray, predicted: np.ndarray):\n",
        "    \"\"\"Mean Error\"\"\"\n",
        "    return np.mean(_error(actual, predicted))\n",
        "\n",
        "\n",
        "def mae(actual: np.ndarray, predicted: np.ndarray):\n",
        "    \"\"\"Mean Absolute Error\"\"\"\n",
        "    return np.mean(np.abs(_error(actual, predicted)))\n",
        "\n",
        "\n",
        "mad = mae  # Mean Absolute Deviation (it is the same as MAE)\n",
        "\n",
        "\n",
        "def gmae(actual: np.ndarray, predicted: np.ndarray):\n",
        "    \"\"\"Geometric Mean Absolute Error\"\"\"\n",
        "    return _geometric_mean(np.abs(_error(actual, predicted)))\n",
        "\n",
        "\n",
        "def mdae(actual: np.ndarray, predicted: np.ndarray):\n",
        "    \"\"\"Median Absolute Error\"\"\"\n",
        "    return np.median(np.abs(_error(actual, predicted)))\n",
        "\n",
        "\n",
        "def mpe(actual: np.ndarray, predicted: np.ndarray):\n",
        "    \"\"\"Mean Percentage Error\"\"\"\n",
        "    return np.mean(_percentage_error(actual, predicted))\n",
        "\n",
        "\n",
        "def mape(actual: np.ndarray, predicted: np.ndarray):\n",
        "    \"\"\"\n",
        "    Mean Absolute Percentage Error\n",
        "    Properties:\n",
        "        + Easy to interpret\n",
        "        + Scale independent\n",
        "        - Biased, not symmetric\n",
        "        - Undefined when actual[t] == 0\n",
        "    Note: result is NOT multiplied by 100\n",
        "    \"\"\"\n",
        "    return np.mean(np.abs(_percentage_error(actual, predicted)))\n",
        "\n",
        "\n",
        "def mdape(actual: np.ndarray, predicted: np.ndarray):\n",
        "    \"\"\"\n",
        "    Median Absolute Percentage Error\n",
        "    Note: result is NOT multiplied by 100\n",
        "    \"\"\"\n",
        "    return np.median(np.abs(_percentage_error(actual, predicted)))\n",
        "\n",
        "\n",
        "def smape(actual: np.ndarray, predicted: np.ndarray):\n",
        "    \"\"\"\n",
        "    Symmetric Mean Absolute Percentage Error\n",
        "    Note: result is NOT multiplied by 100\n",
        "    \"\"\"\n",
        "    return np.mean(\n",
        "        2.0\n",
        "        * np.abs(actual - predicted)\n",
        "        / ((np.abs(actual) + np.abs(predicted)) + EPSILON)\n",
        "    )\n",
        "\n",
        "\n",
        "def smdape(actual: np.ndarray, predicted: np.ndarray):\n",
        "    \"\"\"\n",
        "    Symmetric Median Absolute Percentage Error\n",
        "    Note: result is NOT multiplied by 100\n",
        "    \"\"\"\n",
        "    return np.median(\n",
        "        2.0\n",
        "        * np.abs(actual - predicted)\n",
        "        / ((np.abs(actual) + np.abs(predicted)) + EPSILON)\n",
        "    )\n",
        "\n",
        "\n",
        "def maape(actual: np.ndarray, predicted: np.ndarray):\n",
        "    \"\"\"\n",
        "    Mean Arctangent Absolute Percentage Error\n",
        "    Note: result is NOT multiplied by 100\n",
        "    \"\"\"\n",
        "    return np.mean(np.arctan(np.abs((actual - predicted) / (actual + EPSILON))))\n",
        "\n",
        "\n",
        "def mase(actual: np.ndarray, predicted: np.ndarray, seasonality: int = 1):\n",
        "    \"\"\"\n",
        "    Mean Absolute Scaled Error\n",
        "    Baseline (benchmark) is computed with naive forecasting (shifted by @seasonality)\n",
        "    \"\"\"\n",
        "    return mae(actual, predicted) / mae(\n",
        "        actual[seasonality:], _naive_forecasting(actual, seasonality)\n",
        "    )\n",
        "\n",
        "\n",
        "def std_ae(actual: np.ndarray, predicted: np.ndarray):\n",
        "    \"\"\"Normalized Absolute Error\"\"\"\n",
        "    __mae = mae(actual, predicted)\n",
        "    return np.sqrt(\n",
        "        np.sum(np.square(_error(actual, predicted) - __mae)) / (len(actual) - 1)\n",
        "    )\n",
        "\n",
        "\n",
        "def std_ape(actual: np.ndarray, predicted: np.ndarray):\n",
        "    \"\"\"Normalized Absolute Percentage Error\"\"\"\n",
        "    __mape = mape(actual, predicted)\n",
        "    return np.sqrt(\n",
        "        np.sum(np.square(_percentage_error(actual, predicted) - __mape))\n",
        "        / (len(actual) - 1)\n",
        "    )\n",
        "\n",
        "\n",
        "def rmspe(actual: np.ndarray, predicted: np.ndarray):\n",
        "    \"\"\"\n",
        "    Root Mean Squared Percentage Error\n",
        "    Note: result is NOT multiplied by 100\n",
        "    \"\"\"\n",
        "    return np.sqrt(np.mean(np.square(_percentage_error(actual, predicted))))\n",
        "\n",
        "\n",
        "def rmdspe(actual: np.ndarray, predicted: np.ndarray):\n",
        "    \"\"\"\n",
        "    Root Median Squared Percentage Error\n",
        "    Note: result is NOT multiplied by 100\n",
        "    \"\"\"\n",
        "    return np.sqrt(np.median(np.square(_percentage_error(actual, predicted))))\n",
        "\n",
        "\n",
        "def rmsse(actual: np.ndarray, predicted: np.ndarray, seasonality: int = 1):\n",
        "    \"\"\"Root Mean Squared Scaled Error\"\"\"\n",
        "    q = np.abs(_error(actual, predicted)) / mae(\n",
        "        actual[seasonality:], _naive_forecasting(actual, seasonality)\n",
        "    )\n",
        "    return np.sqrt(np.mean(np.square(q)))\n",
        "\n",
        "\n",
        "def inrse(actual: np.ndarray, predicted: np.ndarray):\n",
        "    \"\"\"Integral Normalized Root Squared Error\"\"\"\n",
        "    return np.sqrt(\n",
        "        np.sum(np.square(_error(actual, predicted)))\n",
        "        / np.sum(np.square(actual - np.mean(actual)))\n",
        "    )\n",
        "\n",
        "\n",
        "def rrse(actual: np.ndarray, predicted: np.ndarray):\n",
        "    \"\"\"Root Relative Squared Error\"\"\"\n",
        "    return np.sqrt(\n",
        "        np.sum(np.square(actual - predicted))\n",
        "        / np.sum(np.square(actual - np.mean(actual)))\n",
        "    )\n",
        "\n",
        "\n",
        "def mre(actual: np.ndarray, predicted: np.ndarray, benchmark: np.ndarray = None):\n",
        "    \"\"\"Mean Relative Error\"\"\"\n",
        "    return np.mean(_relative_error(actual, predicted, benchmark))\n",
        "\n",
        "\n",
        "def rae(actual: np.ndarray, predicted: np.ndarray):\n",
        "    \"\"\"Relative Absolute Error (aka Approximation Error)\"\"\"\n",
        "    return np.sum(np.abs(actual - predicted)) / (\n",
        "        np.sum(np.abs(actual - np.mean(actual))) + EPSILON\n",
        "    )\n",
        "\n",
        "\n",
        "def mrae(actual: np.ndarray, predicted: np.ndarray, benchmark: np.ndarray = None):\n",
        "    \"\"\"Mean Relative Absolute Error\"\"\"\n",
        "    return np.mean(np.abs(_relative_error(actual, predicted, benchmark)))\n",
        "\n",
        "\n",
        "def mdrae(actual: np.ndarray, predicted: np.ndarray, benchmark: np.ndarray = None):\n",
        "    \"\"\"Median Relative Absolute Error\"\"\"\n",
        "    return np.median(np.abs(_relative_error(actual, predicted, benchmark)))\n",
        "\n",
        "\n",
        "def gmrae(actual: np.ndarray, predicted: np.ndarray, benchmark: np.ndarray = None):\n",
        "    \"\"\"Geometric Mean Relative Absolute Error\"\"\"\n",
        "    return _geometric_mean(np.abs(_relative_error(actual, predicted, benchmark)))\n",
        "\n",
        "\n",
        "def mbrae(actual: np.ndarray, predicted: np.ndarray, benchmark: np.ndarray = None):\n",
        "    \"\"\"Mean Bounded Relative Absolute Error\"\"\"\n",
        "    return np.mean(_bounded_relative_error(actual, predicted, benchmark))\n",
        "\n",
        "\n",
        "def umbrae(actual: np.ndarray, predicted: np.ndarray, benchmark: np.ndarray = None):\n",
        "    \"\"\"Unscaled Mean Bounded Relative Absolute Error\"\"\"\n",
        "    __mbrae = mbrae(actual, predicted, benchmark)\n",
        "    return __mbrae / (1 - __mbrae)\n",
        "\n",
        "\n",
        "def mda(actual: np.ndarray, predicted: np.ndarray):\n",
        "    \"\"\"Mean Directional Accuracy\"\"\"\n",
        "    return np.mean(\n",
        "        (\n",
        "            np.sign(actual[1:] - actual[:-1]) == np.sign(predicted[1:] - predicted[:-1])\n",
        "        ).astype(int)\n",
        "    )\n",
        "\n",
        "\n",
        "def bias(actual: np.ndarray, predicted: np.ndarray):\n",
        "    \"\"\"Mean forecast error(or Forecast Bias)\"\"\"\n",
        "    return np.mean(actual - predicted)\n",
        "\n",
        "\n",
        "METRICS = {\n",
        "    \"mse\": mse,\n",
        "    \"rmse\": rmse,\n",
        "    \"nrmse\": nrmse,\n",
        "    \"me\": me,\n",
        "    \"mae\": mae,\n",
        "    \"mad\": mad,\n",
        "    \"gmae\": gmae,\n",
        "    \"mdae\": mdae,\n",
        "    \"mpe\": mpe,\n",
        "    \"mape\": mape,\n",
        "    \"mdape\": mdape,\n",
        "    \"smape\": smape,\n",
        "    \"smdape\": smdape,\n",
        "    \"maape\": maape,\n",
        "    \"mase\": mase,\n",
        "    \"std_ae\": std_ae,\n",
        "    \"std_ape\": std_ape,\n",
        "    \"rmspe\": rmspe,\n",
        "    \"rmdspe\": rmdspe,\n",
        "    \"rmsse\": rmsse,\n",
        "    \"inrse\": inrse,\n",
        "    \"rrse\": rrse,\n",
        "    \"mre\": mre,\n",
        "    \"rae\": rae,\n",
        "    \"mrae\": mrae,\n",
        "    \"mdrae\": mdrae,\n",
        "    \"gmrae\": gmrae,\n",
        "    \"mbrae\": mbrae,\n",
        "    \"umbrae\": umbrae,\n",
        "    \"mda\": mda,\n",
        "    \"bias\": bias,\n",
        "    \"r2\": r2_score,\n",
        "}\n",
        "\n",
        "\n",
        "def evaluate(\n",
        "    actual: np.ndarray, predicted: np.ndarray, metrics=(\"mae\", \"rmse\", \"mape\", \"r2\")\n",
        "):\n",
        "    results = {}\n",
        "    for name in metrics:\n",
        "        try:\n",
        "            results[name] = METRICS[name](actual, predicted)\n",
        "        except Exception as err:\n",
        "            results[name] = np.nan\n",
        "            print(\"Unable to compute metric {0}: {1}\".format(name, err))\n",
        "    return results\n",
        "\n",
        "\n",
        "def evaluate_all(actual: np.ndarray, predicted: np.ndarray):\n",
        "    return evaluate(actual, predicted, metrics=set(METRICS.keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "5kmCAk1zZkps"
      },
      "outputs": [],
      "source": [
        "#Plots\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def bar_metrics(resultsDict):\n",
        "    df = pd.DataFrame.from_dict(resultsDict)\n",
        "    colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
        "    pallette = plt.cm.get_cmap(\"tab20c\", len(df.columns))\n",
        "    colors = [pallette(x) for x in range(len(df.columns))]\n",
        "    color_dict = dict(zip(df.columns, colors))\n",
        "    fig = plt.figure(figsize=(20, 15))\n",
        "\n",
        "    # MAE plot\n",
        "    fig.add_subplot(2, 2, 1)\n",
        "    df.loc[\"mae\"].sort_values().plot(\n",
        "        kind=\"bar\",\n",
        "        colormap=\"Paired\",\n",
        "        color=[color_dict.get(x, \"#333333\") for x in df.loc[\"mae\"].sort_values().index],\n",
        "    )\n",
        "    plt.legend()\n",
        "    plt.title(\"MAE Metric, lower is better\")\n",
        "    fig.add_subplot(2, 2, 2)\n",
        "    df.loc[\"rmse\"].sort_values().plot(\n",
        "        kind=\"bar\",\n",
        "        colormap=\"Paired\",\n",
        "        color=[\n",
        "            color_dict.get(x, \"#333333\") for x in df.loc[\"rmse\"].sort_values().index\n",
        "        ],\n",
        "    )\n",
        "    plt.legend()\n",
        "    plt.title(\"RMSE Metric, lower is better\")\n",
        "    fig.add_subplot(2, 2, 3)\n",
        "    df.loc[\"mape\"].sort_values().plot(\n",
        "        kind=\"bar\",\n",
        "        colormap=\"Paired\",\n",
        "        color=[\n",
        "            color_dict.get(x, \"#333333\") for x in df.loc[\"mape\"].sort_values().index\n",
        "        ],\n",
        "    )\n",
        "    plt.legend()\n",
        "    plt.title(\"MAPE Metric, lower is better\")\n",
        "    fig.add_subplot(2, 2, 4)\n",
        "    df.loc[\"r2\"].sort_values(ascending=False).plot(\n",
        "        kind=\"bar\",\n",
        "        colormap=\"Paired\",\n",
        "        color=[\n",
        "            color_dict.get(x, \"#333333\")\n",
        "            for x in df.loc[\"r2\"].sort_values(ascending=False).index\n",
        "        ],\n",
        "    )\n",
        "    plt.legend()\n",
        "    plt.title(\"R2 Metric, higher is better\")\n",
        "    plt.tight_layout()\n",
        "    # plt.savefig(\"results/metrics.png\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrirs61lZmwO"
      },
      "source": [
        "## Load Data and Manupulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dQaU3h6PZuDC"
      },
      "outputs": [],
      "source": [
        "from cryptocmd import CmcScraper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "noccrlUrZ12e"
      },
      "outputs": [],
      "source": [
        "# initialise scraper without time interval\n",
        "scraper = CmcScraper(\"BTC\")\n",
        "# get raw data as list of list\n",
        "headers, data = scraper.get_data()\n",
        "# get data in a json format\n",
        "xrp_json_data = scraper.get_data(\"json\")\n",
        "# Pandas dataFrame for the same data\n",
        "df_full = scraper.get_dataframe()\n",
        "df_full['Date'] =  pd.to_datetime(df_full['Date'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gljQ0xkuZ100"
      },
      "outputs": [],
      "source": [
        "df_full.drop(['Open','High','Low', 'Volume'],axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "U0f_lsiRZ1w6"
      },
      "outputs": [],
      "source": [
        "a_7=[]\n",
        "b_15=[]\n",
        "c_30=[]\n",
        "d_45=[]\n",
        "e_60=[]\n",
        "f_90=[]\n",
        "base = datetime.datetime.today().date()\n",
        "for x in range(0, 7):\n",
        "      a_7.append(base + datetime.timedelta(days=x))\n",
        "for x in range(0, 15):\n",
        "      b_15.append(base + datetime.timedelta(days=x))\n",
        "for x in range(0, 30):\n",
        "      c_30.append(base + datetime.timedelta(days=x))\n",
        "for x in range(0, 45):\n",
        "      d_45.append(base + datetime.timedelta(days=x))\n",
        "for x in range(0, 60):\n",
        "      e_60.append(base + datetime.timedelta(days=x))\n",
        "for x in range(0, 90):\n",
        "      f_90.append(base + datetime.timedelta(days=x))\n",
        "df_next7days = pd.DataFrame({\"Date\":a_7})\n",
        "df_next15days = pd.DataFrame({\"Date\":b_15})\n",
        "df_next30days = pd.DataFrame({\"Date\":c_30})\n",
        "df_next45days = pd.DataFrame({\"Date\":d_45})\n",
        "df_next60days = pd.DataFrame({\"Date\":e_60})\n",
        "df_next90days = pd.DataFrame({\"Date\":f_90})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCX8BtNlZ1q5",
        "outputId": "d99af063-760d-4b02-807e-1d2f967da348"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7 Days ago:  2022-10-27\n",
            "15 Days ago:  2022-10-19\n",
            "30 Days ago:  2022-10-04\n",
            "45 Days ago:  2022-09-19\n",
            "60 Days ago:  2022-09-04\n",
            "90 Days ago:  2022-08-05\n"
          ]
        }
      ],
      "source": [
        "week_ago_7 = datetime.date.today() - datetime.timedelta(days=7)\n",
        "print(\"7 Days ago: \",week_ago_7.strftime('%Y-%m-%d'))\n",
        "week_ago_15 = datetime.date.today() - datetime.timedelta(days=15)\n",
        "print(\"15 Days ago: \",week_ago_15.strftime('%Y-%m-%d'))\n",
        "week_ago_30 = datetime.date.today() - datetime.timedelta(days=30)\n",
        "print(\"30 Days ago: \",week_ago_30.strftime('%Y-%m-%d'))\n",
        "week_ago_45 = datetime.date.today() - datetime.timedelta(days=45)\n",
        "print(\"45 Days ago: \",week_ago_45.strftime('%Y-%m-%d'))\n",
        "week_ago_60 = datetime.date.today() - datetime.timedelta(days=60)\n",
        "print(\"60 Days ago: \",week_ago_60.strftime('%Y-%m-%d'))\n",
        "week_ago_90 = datetime.date.today() - datetime.timedelta(days=90)\n",
        "print(\"90 Days ago: \",week_ago_90.strftime('%Y-%m-%d'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "78e4METYZ1Yq"
      },
      "outputs": [],
      "source": [
        "df = df_full[(df_full['Date'] >= '2021-01-01') & (df_full['Date'] <= datetime.date.today().strftime('%Y-%m-%d'))]\n",
        "df_predict_7 = df_next7days.copy()\n",
        "df_predict_15 = df_next15days.copy()\n",
        "df_predict_30 = df_next30days.copy()\n",
        "df_predict_45 = df_next45days.copy()\n",
        "df_predict_60 = df_next60days.copy()\n",
        "df_predict_90 = df_next90days.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "1WBvpn7dZ1XN"
      },
      "outputs": [],
      "source": [
        "df_full.index = df_full.Date\n",
        "df_full.drop('Date',axis=1,inplace=True)\n",
        "\n",
        "df.index = df.Date\n",
        "df.drop('Date',axis=1,inplace=True)\n",
        "\n",
        "df_predict_7.index = df_predict_7.Date\n",
        "df_predict_7.drop('Date',axis=1,inplace=True)\n",
        "df_predict_15.index = df_predict_15.Date\n",
        "df_predict_15.drop('Date',axis=1,inplace=True)\n",
        "df_predict_30.index = df_predict_30.Date\n",
        "df_predict_30.drop('Date',axis=1,inplace=True)\n",
        "df_predict_45.index = df_predict_45.Date\n",
        "df_predict_45.drop('Date',axis=1,inplace=True)\n",
        "df_predict_60.index = df_predict_60.Date\n",
        "df_predict_60.drop('Date',axis=1,inplace=True)\n",
        "df_predict_90.index = df_predict_90.Date\n",
        "df_predict_90.drop('Date',axis=1,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "awa0rs5KZ1St"
      },
      "outputs": [],
      "source": [
        "df_predict_7[\"Market Cap\"] = df[\"Market Cap\"].tolist()[:7]\n",
        "df_predict_15[\"Market Cap\"] = df[\"Market Cap\"].tolist()[:15]\n",
        "df_predict_30[\"Market Cap\"] = df[\"Market Cap\"].tolist()[:30]\n",
        "df_predict_45[\"Market Cap\"] = df[\"Market Cap\"].tolist()[:45]\n",
        "df_predict_60[\"Market Cap\"] = df[\"Market Cap\"].tolist()[:60]\n",
        "df_predict_90[\"Market Cap\"] = df[\"Market Cap\"].tolist()[:90]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0Qbie6JUZ1Lj"
      },
      "outputs": [],
      "source": [
        "df['Close:7 days rolling']=df['Close'].rolling(7).mean()\n",
        "df['Market Cap:7 days rolling']=df['Market Cap'].rolling(7).mean()\n",
        "\n",
        "df['Close:15 days rolling']=df['Close'].rolling(15).mean()\n",
        "df['Market Cap:15 days rolling']=df['Market Cap'].rolling(15).mean()\n",
        "\n",
        "df['Close:30 days rolling']=df['Close'].rolling(30).mean()\n",
        "df['Market Cap:30 days rolling']=df['Market Cap'].rolling(30).mean()\n",
        "\n",
        "df['Close:45 days rolling']=df['Close'].rolling(45).mean()\n",
        "df['Market Cap:45 days rolling']=df['Market Cap'].rolling(45).mean()\n",
        "\n",
        "df['Close:60 days rolling']=df['Close'].rolling(60).mean()\n",
        "df['Market Cap:60 days rolling']=df['Market Cap'].rolling(60).mean()\n",
        "\n",
        "df['Close:90 days rolling']=df['Close'].rolling(90).mean()\n",
        "df['Market Cap:90 days rolling']=df['Market Cap'].rolling(90).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "dz7pEctLOHrg"
      },
      "outputs": [],
      "source": [
        "df.drop(['Market Cap','Close'],axis=1,inplace=True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "1QseWr2LN1Oj"
      },
      "outputs": [],
      "source": [
        "df_7 = df[['Close:7 days rolling', 'Market Cap:7 days rolling']]\n",
        "df_15 = df[['Close:15 days rolling', 'Market Cap:15 days rolling']]\n",
        "df_30 = df[['Close:30 days rolling', 'Market Cap:30 days rolling']]\n",
        "df_45 = df[['Close:45 days rolling', 'Market Cap:45 days rolling']]\n",
        "df_60 = df[['Close:60 days rolling', 'Market Cap:60 days rolling']]\n",
        "df_90 = df[['Close:90 days rolling', 'Market Cap:90 days rolling']]\n",
        "\n",
        "df_7.dropna(inplace=True)\n",
        "df_15.dropna(inplace=True)\n",
        "df_30.dropna(inplace=True)\n",
        "df_45.dropna(inplace=True)\n",
        "df_60.dropna(inplace=True)\n",
        "df_90.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "JQMfoRqLiH7a"
      },
      "outputs": [],
      "source": [
        "# ADD time features to our model\n",
        "def create_time_features(df, target=None):\n",
        "    \"\"\"\n",
        "    Creates time series features from datetime index\n",
        "    \"\"\"\n",
        "    df['date'] = df.index\n",
        "    df['date'] =  pd.to_datetime(df['date'])\n",
        "    df['hour'] = df['date'].dt.hour\n",
        "    df['dayofweek'] = df['date'].dt.dayofweek\n",
        "    df['quarter'] = df['date'].dt.quarter\n",
        "    df['month'] = df['date'].dt.month\n",
        "    df['year'] = df['date'].dt.year\n",
        "    df['dayofyear'] = df['date'].dt.dayofyear\n",
        "    df['sin_day'] = np.sin(df['dayofyear'])\n",
        "    df['cos_day'] = np.cos(df['dayofyear'])\n",
        "    df['dayofmonth'] = df['date'].dt.day\n",
        "    df['weekofyear'] = df['date'].dt.weekofyear\n",
        "    X = df.drop(['date'], axis=1)\n",
        "    if target:\n",
        "        y = df[target]\n",
        "        X = X.drop([target], axis=1)\n",
        "        return X, y\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "KUkENmSuiJ2c"
      },
      "outputs": [],
      "source": [
        "X_train_df_7, y_train_7 = create_time_features(df_7, target='Close:7 days rolling')\n",
        "X_test_df_7 = create_time_features(df_predict_7)\n",
        "\n",
        "X_train_df_15, y_train_15 = create_time_features(df_15, target='Close:15 days rolling')\n",
        "X_test_df_15 = create_time_features(df_predict_15)\n",
        "\n",
        "X_train_df_30, y_train_30 = create_time_features(df_30, target='Close:30 days rolling')\n",
        "X_test_df_30 = create_time_features(df_predict_30)\n",
        "\n",
        "X_train_df_45, y_train_45 = create_time_features(df_45, target='Close:45 days rolling')\n",
        "X_test_df_45 = create_time_features(df_predict_45)\n",
        "\n",
        "X_train_df_60, y_train_60 = create_time_features(df_60, target='Close:60 days rolling')\n",
        "X_test_df_60 = create_time_features(df_predict_60)\n",
        "\n",
        "X_train_df_90, y_train_90 = create_time_features(df_90, target='Close:90 days rolling')\n",
        "X_test_df_90 = create_time_features(df_predict_90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "DuIxE3SUiRqI"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train_df_7)\n",
        "X_train_7 = scaler.transform(X_train_df_7)\n",
        "X_test_7 = scaler.transform(X_test_df_7)\n",
        "X_train_df_7 = pd.DataFrame(X_train_7, columns=X_train_df_7.columns)\n",
        "X_test_df_7 = pd.DataFrame(X_test_7, columns=X_test_df_7.columns)\n",
        "\n",
        "scaler.fit(X_train_df_15)\n",
        "X_train_15 = scaler.transform(X_train_df_15)\n",
        "X_test_15 = scaler.transform(X_test_df_15)\n",
        "X_train_df_15 = pd.DataFrame(X_train_15, columns=X_train_df_15.columns)\n",
        "X_test_df_15 = pd.DataFrame(X_test_15, columns=X_test_df_15.columns)\n",
        "\n",
        "scaler.fit(X_train_df_30)\n",
        "X_train_30 = scaler.transform(X_train_df_30)\n",
        "X_test_30 = scaler.transform(X_test_df_30)\n",
        "X_train_df_30 = pd.DataFrame(X_train_30, columns=X_train_df_30.columns)\n",
        "X_test_df_30 = pd.DataFrame(X_test_30, columns=X_test_df_30.columns)\n",
        "\n",
        "scaler.fit(X_train_df_45)\n",
        "X_train_45 = scaler.transform(X_train_df_45)\n",
        "X_test_45 = scaler.transform(X_test_df_45)\n",
        "X_train_df_45 = pd.DataFrame(X_train_45, columns=X_train_df_45.columns)\n",
        "X_test_df_45 = pd.DataFrame(X_test_45, columns=X_test_df_45.columns)\n",
        "\n",
        "scaler.fit(X_train_df_60)\n",
        "X_train_60 = scaler.transform(X_train_df_60)\n",
        "X_test_60 = scaler.transform(X_test_df_60)\n",
        "X_train_df_60 = pd.DataFrame(X_train_60, columns=X_train_df_60.columns)\n",
        "X_test_df_60 = pd.DataFrame(X_test_60, columns=X_test_df_60.columns)\n",
        "\n",
        "scaler.fit(X_train_df_90)\n",
        "X_train_90 = scaler.transform(X_train_df_90)\n",
        "X_test_90 = scaler.transform(X_test_df_90)\n",
        "X_train_df_90 = pd.DataFrame(X_train_90, columns=X_train_df_90.columns)\n",
        "X_test_df_90 = pd.DataFrame(X_test_90, columns=X_test_df_90.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X57tFRnAiXTW"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "HG8iNIlPiWbC"
      },
      "outputs": [],
      "source": [
        "resultsDict = {}\n",
        "predictionsDict_7 = {}\n",
        "predictionsDict_15 = {}\n",
        "predictionsDict_30 = {}\n",
        "predictionsDict_45 = {}\n",
        "predictionsDict_60 = {}\n",
        "predictionsDict_90 = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "8KM384eXiT8E"
      },
      "outputs": [],
      "source": [
        "reg = RandomForestRegressor(max_depth=150, random_state=101)\n",
        "reg.fit(X_train_7, y_train_7)\n",
        "yhat_7 = reg.predict(X_test_7)\n",
        "predictionsDict_7['Randomforest_7'] = yhat_7\n",
        "\n",
        "reg.fit(X_train_15, y_train_15)\n",
        "yhat_15 = reg.predict(X_test_15)\n",
        "predictionsDict_15['Randomforest_15'] = yhat_15\n",
        "\n",
        "reg.fit(X_train_30, y_train_30)\n",
        "yhat_30 = reg.predict(X_test_30)\n",
        "predictionsDict_30['Randomforest_30'] = yhat_30\n",
        "\n",
        "reg.fit(X_train_45, y_train_45)\n",
        "yhat_45 = reg.predict(X_test_45)\n",
        "predictionsDict_45['Randomforest_45'] = yhat_45\n",
        "\n",
        "reg.fit(X_train_60, y_train_60)\n",
        "yhat_60 = reg.predict(X_test_60)\n",
        "predictionsDict_60['Randomforest_60'] = yhat_60\n",
        "\n",
        "reg.fit(X_train_90, y_train_90)\n",
        "yhat_90 = reg.predict(X_test_90)\n",
        "predictionsDict_90['Randomforest_90'] = yhat_90"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "0xJOPKQjif1c"
      },
      "outputs": [],
      "source": [
        "reg = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=3000)\n",
        "reg.fit(X_train_7, y_train_7,verbose=False)\n",
        "yhat_7 = reg.predict(X_test_7)\n",
        "predictionsDict_7['XGBoost_7'] = yhat_7\n",
        "\n",
        "reg.fit(X_train_15, y_train_15,verbose=False)\n",
        "yhat_15 = reg.predict(X_test_15)\n",
        "predictionsDict_15['XGBoost_15'] = yhat_15\n",
        "\n",
        "reg.fit(X_train_30, y_train_30,verbose=False)\n",
        "yhat_30 = reg.predict(X_test_30)\n",
        "predictionsDict_30['XGBoost_30'] = yhat_30\n",
        "\n",
        "reg.fit(X_train_45, y_train_45,verbose=False)\n",
        "yhat_45 = reg.predict(X_test_45)\n",
        "predictionsDict_45['XGBoost_45'] = yhat_45\n",
        "\n",
        "reg.fit(X_train_60, y_train_60,verbose=False)\n",
        "yhat_60 = reg.predict(X_test_60)\n",
        "predictionsDict_60['XGBoost_60'] = yhat_60\n",
        "\n",
        "reg.fit(X_train_90, y_train_90,verbose=False)\n",
        "yhat_90 = reg.predict(X_test_90)\n",
        "predictionsDict_90['XGBoost_90'] = yhat_90"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "UH5BmCLGiqFR"
      },
      "outputs": [],
      "source": [
        "reg = linear_model.Lasso(alpha=0.3)\n",
        "reg.fit(X_train_7, y_train_7)\n",
        "yhat_7 = reg.predict(X_test_7)\n",
        "predictionsDict_7['Lasso_7'] = yhat_7\n",
        "\n",
        "reg.fit(X_train_15, y_train_15)\n",
        "yhat_15 = reg.predict(X_test_15)\n",
        "predictionsDict_15['Lasso_15'] = yhat_15\n",
        "\n",
        "reg.fit(X_train_30, y_train_30)\n",
        "yhat_30 = reg.predict(X_test_30)\n",
        "predictionsDict_30['Lasso_30'] = yhat_30\n",
        "\n",
        "reg.fit(X_train_45, y_train_45)\n",
        "yhat_45 = reg.predict(X_test_45)\n",
        "predictionsDict_45['Lasso_45'] = yhat_45\n",
        "\n",
        "reg.fit(X_train_60, y_train_60)\n",
        "yhat_60 = reg.predict(X_test_60)\n",
        "predictionsDict_60['Lasso_60'] = yhat_60\n",
        "\n",
        "reg.fit(X_train_90, y_train_90)\n",
        "yhat_90 = reg.predict(X_test_90)\n",
        "predictionsDict_90['Lasso_90'] = yhat_90"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCmkQDIGpTsY"
      },
      "source": [
        "## Save Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ftlx2A3xpunj"
      },
      "outputs": [],
      "source": [
        "df_dictionary_7 = pd.DataFrame.from_dict(predictionsDict_7['XGBoost_7']).rename(columns={0:'Values'})\n",
        "Final_df_Output_7 = pd.concat([df_next7days, df_dictionary_7], axis=1)\n",
        "\n",
        "df_dictionary_15 = pd.DataFrame.from_dict(predictionsDict_15['XGBoost_15']).rename(columns={0:'Values'})\n",
        "Final_df_Output_15 = pd.concat([df_next15days, df_dictionary_15], axis=1)\n",
        "\n",
        "df_dictionary_30 = pd.DataFrame.from_dict(predictionsDict_30['XGBoost_30']).rename(columns={0:'Values'})\n",
        "Final_df_Output_30 = pd.concat([df_next30days, df_dictionary_30], axis=1)\n",
        "\n",
        "df_dictionary_45 = pd.DataFrame.from_dict(predictionsDict_45['XGBoost_45']).rename(columns={0:'Values'})\n",
        "Final_df_Output_45 = pd.concat([df_next45days, df_dictionary_45], axis=1)\n",
        "\n",
        "df_dictionary_60 = pd.DataFrame.from_dict(predictionsDict_60['XGBoost_60']).rename(columns={0:'Values'})\n",
        "Final_df_Output_60 = pd.concat([df_next60days, df_dictionary_60], axis=1)\n",
        "\n",
        "df_dictionary_90 = pd.DataFrame.from_dict(predictionsDict_90['XGBoost_90']).rename(columns={0:'Values'})\n",
        "Final_df_Output_90 = pd.concat([df_next90days, df_dictionary_90], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "qyNJgtcWk5U8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "120eef4b-a7a8-47c1-d9bb-ca203e797256"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "33iSie4NYH39"
      },
      "outputs": [],
      "source": [
        "Final_df_Output_7.to_csv('/drive/My Drive/Bitcoin Prediction/next7days.csv',index=False)\n",
        "Final_df_Output_15.to_csv('/drive/My Drive/Bitcoin Prediction/next15days.csv',index=False)\n",
        "Final_df_Output_30.to_csv('/drive/My Drive/Bitcoin Prediction/next30days.csv',index=False)\n",
        "Final_df_Output_45.to_csv('/drive/My Drive/Bitcoin Prediction/next45days.csv',index=False)\n",
        "Final_df_Output_60.to_csv('/drive/My Drive/Bitcoin Prediction/next60days.csv',index=False)\n",
        "Final_df_Output_90.to_csv('/drive/My Drive/Bitcoin Prediction/next90days.csv',index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Nstigiz9ZHDe",
        "DLOncNpJZNhS",
        "yrirs61lZmwO",
        "X57tFRnAiXTW"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}